{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85647254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\viviz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a421663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ==========================================\n",
    "# 1. í™˜ê²½ ì„¤ì • (ìˆ˜ì •í•  ë¶€ë¶„)\n",
    "# ==========================================\n",
    "DATA_PATH = \"./dataset\"   # ë°ì´í„°ê°€ ë“¤ì–´ìˆëŠ” ìµœìƒìœ„ í´ë”\n",
    "MAX_FRAMES = 100          # ì˜ìƒ í•˜ë‚˜ë‹¹ ìµœëŒ€ ê¸¸ì´ (í”„ë ˆì„ ìˆ˜)\n",
    "IMG_WIDTH = 1920          # ì¢Œí‘œ ì •ê·œí™”ë¥¼ ìœ„í•œ ì˜ìƒ ê°€ë¡œ í¬ê¸°\n",
    "IMG_HEIGHT = 1080         # ì¢Œí‘œ ì •ê·œí™”ë¥¼ ìœ„í•œ ì˜ìƒ ì„¸ë¡œ í¬ê¸°\n",
    "\n",
    "# ==========================================\n",
    "# 2. ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ (JSON -> ìˆ«ì ë³€í™˜)\n",
    "# ==========================================\n",
    "def extract_keypoints(json_path):\n",
    "    \"\"\" JSON íŒŒì¼ì—ì„œ ëª¸í†µ, ì™¼ì†, ì˜¤ë¥¸ì† ì¢Œí‘œë¥¼ êº¼ë‚´ 0~1 ì‚¬ì´ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤. \"\"\"\n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    except:\n",
    "        return np.zeros(134) # íŒŒì¼ì´ ê¹¨ì¡Œìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€\n",
    "\n",
    "    # ë°ì´í„°ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸\n",
    "    if not data.get('people'):\n",
    "        return np.zeros(134) \n",
    "\n",
    "    # people ë°ì´í„° í˜•ì‹ì´ ë¦¬ìŠ¤íŠ¸ì¸ì§€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸\n",
    "    people_data = data['people']\n",
    "    person = people_data[0] if isinstance(people_data, list) else people_data\n",
    "\n",
    "    pose = person.get('pose_keypoints_2d', [])\n",
    "    lh = person.get('hand_left_keypoints_2d', [])\n",
    "    rh = person.get('hand_right_keypoints_2d', [])\n",
    "\n",
    "    # ì¢Œí‘œ ì¶”ì¶œ ë° ì •ê·œí™” í•¨ìˆ˜\n",
    "    def process_points(points, count):\n",
    "        xy = []\n",
    "        if len(points) < count * 3:\n",
    "            return [0.0] * (count * 2) # ë°ì´í„° ë¶€ì¡±í•˜ë©´ 0ìœ¼ë¡œ ì±„ì›€\n",
    "        \n",
    "        for i in range(0, count * 3, 3):\n",
    "            x = points[i] / IMG_WIDTH\n",
    "            y = points[i+1] / IMG_HEIGHT\n",
    "            xy.extend([x, y])\n",
    "        return xy\n",
    "\n",
    "    # Pose(25ê°œ) + Left Hand(21ê°œ) + Right Hand(21ê°œ) = ì´ 67ê°œ ì  -> 134ê°œ ì¢Œí‘œ\n",
    "    feature_vector = []\n",
    "    feature_vector.extend(process_points(pose, 25))\n",
    "    feature_vector.extend(process_points(lh, 21))\n",
    "    feature_vector.extend(process_points(rh, 21))\n",
    "\n",
    "    return np.array(feature_vector)\n",
    "\n",
    "# ==========================================\n",
    "# 3. ë°ì´í„°ì…‹ ë¡œë”© (ë‹¨ì–´ í†µí•© ê¸°ëŠ¥ í¬í•¨)\n",
    "# ==========================================\n",
    "def load_dataset(base_path):\n",
    "    X_data = []\n",
    "    Y_data = []\n",
    "\n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"âŒ ì˜¤ë¥˜: '{base_path}' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return [], []\n",
    "\n",
    "    folders = os.listdir(base_path)\n",
    "    print(f\"ğŸ“‚ ì´ {len(folders)}ê°œì˜ í´ë”ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë¡œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "    for folder_name in folders:\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        # 1. ì •ë‹µì§€(morpheme.json) ì°¾ê¸°\n",
    "        morpheme_file = None\n",
    "        for file in os.listdir(folder_path):\n",
    "            # ì •ë©´(_F_)ì´ë©´ì„œ morpheme íŒŒì¼ì¸ ê²ƒ ì°¾ê¸°\n",
    "            if \"_F_\" in file and file.endswith(\"morpheme.json\"):\n",
    "                morpheme_file = file\n",
    "                break\n",
    "        \n",
    "        if morpheme_file is None:\n",
    "            print(f\"âš ï¸ ê²½ê³ : {folder_name}ì— morpheme íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            continue\n",
    "\n",
    "        # 2. íŒŒì¼ ì—´ì–´ì„œ ì •ë³´ ì½ê¸°\n",
    "        with open(os.path.join(folder_path, morpheme_file), 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                m_data = json.load(f)\n",
    "                raw_label = m_data['data'][0]['attributes'][0]['name'] # ì›ë³¸ ë‹¨ì–´ ì´ë¦„\n",
    "                \n",
    "                # ========================================================\n",
    "                # [ì¤‘ìš”] ë‹¨ì–´ ì´ë¦„ í†µì¼í•˜ê¸° (ì‚¬ìš©ì ë§ì¶¤ ì„¤ì •)\n",
    "                # ========================================================\n",
    "                if raw_label in [\"ì•ˆë…•í•˜ì„¸ìš”\", \"ì•ˆë…•\"]:\n",
    "                    label = \"ì•ˆë…•\"\n",
    "                elif raw_label in [\"ê°ì‚¬í•©ë‹ˆë‹¤\", \"ê°ì‚¬\"]:\n",
    "                    label = \"ê°ì‚¬\"\n",
    "                elif raw_label in [\"ë¯¸ì•ˆí•©ë‹ˆë‹¤\", \"ë¯¸ì•ˆ\"]:\n",
    "                    label = \"ë¯¸ì•ˆ\"\n",
    "                elif raw_label == \"ë‚˜\":\n",
    "                    label = \"ë‚˜\"\n",
    "                elif raw_label == \"ì¢‹ë‹¤\":\n",
    "                    label = \"ì¢‹ë‹¤\"\n",
    "                else:\n",
    "                    label = raw_label # ê·¸ ì™¸ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "                \n",
    "                # ì‹œì‘/ì¢…ë£Œ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°\n",
    "                start_time = float(m_data['data'][0]['start'])\n",
    "                end_time = float(m_data['data'][0]['end'])\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ ë°ì´í„° ì½ê¸° ì˜¤ë¥˜ ({folder_name}): {e}\")\n",
    "                continue\n",
    "\n",
    "        print(f\"   Reading: [{label}] (ì›ë³¸: {raw_label})\")\n",
    "\n",
    "        # 3. ì‹œê°„ -> í”„ë ˆì„ ë²ˆí˜¸ë¡œ ë³€í™˜\n",
    "        start_frame = int(start_time * 30)\n",
    "        end_frame = int(end_time * 30)\n",
    "\n",
    "        sequence = []\n",
    "        \n",
    "        # 4. í•´ë‹¹ êµ¬ê°„ì˜ Keypoint íŒŒì¼ë“¤ ì½ì–´ì˜¤ê¸°\n",
    "        for frame_idx in range(start_frame, end_frame + 1):\n",
    "            # íŒŒì¼ëª… ê·œì¹™: ..._F_...00052_keypoints.json\n",
    "            suffix = f\"_{frame_idx:012d}_keypoints.json\"\n",
    "            \n",
    "            target_json = None\n",
    "            for file in os.listdir(folder_path):\n",
    "                if \"_F_\" in file and file.endswith(suffix):\n",
    "                    target_json = file\n",
    "                    break\n",
    "            \n",
    "            if target_json:\n",
    "                kp_vector = extract_keypoints(os.path.join(folder_path, target_json))\n",
    "                sequence.append(kp_vector)\n",
    "\n",
    "        # ë°ì´í„°ê°€ ì˜ ëª¨ì˜€ìœ¼ë©´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "        if len(sequence) > 0:\n",
    "            X_data.append(sequence)\n",
    "            Y_data.append(label)\n",
    "\n",
    "    return X_data, Y_data\n",
    "\n",
    "# ==========================================\n",
    "# 4. í•™ìŠµ ì‹¤í–‰\n",
    "# ==========================================\n",
    "\n",
    "# 1) ë°ì´í„° ë¡œë“œ\n",
    "X, Y = load_dataset(DATA_PATH)\n",
    "\n",
    "if len(X) == 0:\n",
    "    print(\"\\nâŒ í•™ìŠµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤! dataset í´ë” êµ¬ì„±ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    exit()\n",
    "\n",
    "# 2) ë°ì´í„° ê°€ê³µ (íŒ¨ë”© & ì¸ì½”ë”©)\n",
    "X_padded = pad_sequences(X, maxlen=MAX_FRAMES, padding='post', dtype='float32')\n",
    "X_array = np.array(X_padded)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "Y_encoded = encoder.fit_transform(Y)\n",
    "Y_onehot = to_categorical(Y_encoded)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(f\" - í•™ìŠµ ë°ì´í„° ìˆ˜: {len(X_array)}ê°œ\")\n",
    "print(f\" - í•™ìŠµí•  ë‹¨ì–´ë“¤: {encoder.classes_}\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# 3) GRU ëª¨ë¸ ì„¤ê³„\n",
    "model = Sequential()\n",
    "model.add(GRU(64, return_sequences=True, activation='relu', input_shape=(MAX_FRAMES, 134)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(128, return_sequences=False, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(encoder.classes_), activation='softmax')) # ë‹¨ì–´ ê°œìˆ˜ë§Œí¼ ì¶œë ¥\n",
    "\n",
    "# 4) ì»´íŒŒì¼ ë° í•™ìŠµ\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"ğŸš€ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "model.fit(X_array, Y_onehot, epochs=50, batch_size=2, validation_split=0.1)\n",
    "\n",
    "# 5) ì €ì¥\n",
    "model.save('my_sign_language_model.h5')\n",
    "np.save('classes.npy', encoder.classes_)\n",
    "\n",
    "print(\"\\nğŸ‰ í•™ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ëë‚¬ìŠµë‹ˆë‹¤! (ëª¨ë¸ ì €ì¥ë¨)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
